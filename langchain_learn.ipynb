{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d159a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "os.environ['OPENAI_API_KEY'] = \"sk-tdStLQVkiu1YaAGdhcWdrV4HkSij0aWVS7Lt7ZYkhWWp60Ib\"\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cb1b29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model = 'gpt-3.5-turbo'):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    client = OpenAI(base_url=\"https://api.cphone.vip/v1\")\n",
    "    response = client.chat.completions.create(\n",
    "        model = model,\n",
    "        messages = messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf9b4286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I’m an AI language model created by OpenAI. I can help answer questions, provide explanations, assist with writing, and much more. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "print(get_completion(\"What are you\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f808c60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Arr, I be fuming that me blender lid flew off and \n",
    "splattered me kitchen walls with smoothie! And to make \n",
    "matters worse, the warranty don't cover the cost of \n",
    "cleaning up me kitchen. I need yer help right now, matey!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9591efc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "style = \"Chinese in a calm and offended tone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9efdfbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tanslate the text that is  delimited by triple backticks into a style\n",
      "that is Chinese in a calm and offended tone.\n",
      "text: ```\n",
      "Arr, I be fuming that me blender lid flew off and \n",
      "splattered me kitchen walls with smoothie! And to make \n",
      "matters worse, the warranty don't cover the cost of \n",
      "cleaning up me kitchen. I need yer help right now, matey!\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\" Tanslate the text that is  \\\n",
    "delimited by triple backticks into a style\n",
    "that is {style}.\n",
    "text: ```{customer_email}```\n",
    "\"\"\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60aa3b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_completion(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f9fc6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'唉，我真是气炸了，搅拌机的盖子竟然飞了出去，把厨房的墙壁都溅满了果昔！更糟糕的是，保修竟然不包括清理厨房的费用。现在我真是需要你的帮助，朋友！'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "737d6e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(profile={'max_input_tokens': 16385, 'max_output_tokens': 4096, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': False, 'structured_output': False, 'image_url_inputs': False, 'pdf_inputs': False, 'pdf_tool_message': False, 'image_tool_message': False, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x000001D56325F110>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001D564B5ECF0>, root_client=<openai.OpenAI object at 0x000001D5631C7D10>, root_async_client=<openai.AsyncOpenAI object at 0x000001D5631E1160>, temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.cphone.vip/v1')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "chat = ChatOpenAI(\n",
    "    api_key = \"sk-tdStLQVkiu1YaAGdhcWdrV4HkSij0aWVS7Lt7ZYkhWWp60Ib\",\n",
    "    base_url=\"https://api.cphone.vip/v1\",\n",
    "    temperature=0,\n",
    "    )\n",
    "chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b34706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_string = \"\"\" Tanslate the text that is\n",
    "delimited by triple backticks into a style\n",
    "that is {style}.\n",
    "text: ```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4a52fa5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'template_string' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m prompt_template = ChatPromptTemplate.from_template(\u001b[43mtemplate_string\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'template_string' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52e8deb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['style', 'text'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['style', 'text'], input_types={}, partial_variables={}, template=' Tanslate the text that is\\ndelimited by triple backticks into a style\\nthat is {style}.\\ntext: ```{text}```\\n'), additional_kwargs={})])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f45a89db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['style', 'text']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b615a712",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_style = \"Chinese in a calm and offended tone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b54bd908",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Arr, I be fuming that me blender lid flew off and \n",
    "splattered me kitchen walls with smoothie! And to make \n",
    "matters worse, the warranty don't cover the cost of \n",
    "cleaning up me kitchen. I need yer help right now, matey!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30668769",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_messages = prompt_template.format_messages(\n",
    "    style = customer_style,\n",
    "    text = customer_email\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4255bfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'langchain_core.messages.human.HumanMessage'>\n"
     ]
    }
   ],
   "source": [
    "print(type(customer_messages))\n",
    "print(type(customer_messages[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04cf6542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\" Tanslate the text that is\\ndelimited by triple backticks into a style\\nthat is Chinese in a calm and offended tone.\\ntext: ```\\nArr, I be fuming that me blender lid flew off and \\nsplattered me kitchen walls with smoothie! And to make \\nmatters worse, the warranty don't cover the cost of \\ncleaning up me kitchen. I need yer help right now, matey!\\n```\\n\" additional_kwargs={} response_metadata={}\n"
     ]
    }
   ],
   "source": [
    "print(customer_messages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e639628b",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_response = chat.invoke(customer_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6323a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "唉，我真是气炸了，搅拌机的盖子竟然飞了出去，把厨房的墙壁全都溅满了果昔！更糟糕的是，保修竟然不包括清理厨房的费用。真是让人难以接受，朋友，我现在真的需要你的帮助。\n"
     ]
    }
   ],
   "source": [
    "print(customer_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37cfa15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_reply = \"\"\"They key customer,\n",
    "the warranty does not cover\n",
    "cleaning up the kitchen\n",
    "because it's your fault that\n",
    "you missed your blender\n",
    "and forgetting to put the lid on before\n",
    "starting the blender.\n",
    "Tough luck! See ya!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f7d9c5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_style_pirate = \"\"\"a polite tone that speaks in English Pirate\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2791aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_messages = prompt_template.format_messages(\n",
    "    style = service_style_pirate,\n",
    "    text = service_reply\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "459f6d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_response = chat.invoke(service_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46cbd952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ahoy, esteemed customer,  \n",
      "Pray understand, the warranty be not coverin’ the tidyin’ of the galley,  \n",
      "for ’tis yer own fault ye missed yer blender,  \n",
      "and forgot to secure the lid afore ye set sail with the blender.  \n",
      "Aye, tough luck it be! Fair winds to ye!\n"
     ]
    }
   ],
   "source": [
    "print(service_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6ac0ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\ '\n",
      "C:\\Users\\18850\\AppData\\Local\\Temp\\ipykernel_9056\\2130132809.py:1: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  customer_review = \"\"\"This leaf blower is pretty amazing. It has four settings:\\ candle blower, gentle breeze, windy city, and tornado. \\\n"
     ]
    }
   ],
   "source": [
    "customer_review = \"\"\"This leaf blower is pretty amazing. It has four settings:\\ candle blower, gentle breeze, windy city, and tornado. \\\n",
    "It arrived in two days, just in time for my wife's \\\n",
    "anniversary present. \\\n",
    "I think my wife liked it so much she was speechless. \\\n",
    "So far I've been the only one using it, and I've been \\\n",
    "using it every other morning to clear the leaves on our law \\\n",
    "It's slightly more expensive than the other leaf blowers \\\n",
    "out there, but I think it's worth it for the extra features.\"\"\"\n",
    "\n",
    "review_template = \"\"\"For the following text, extract the following information:\n",
    "gift: Was the item purchased as a gift for someone else? Ans\n",
    "delivery_days: How many days did it take for the product to \n",
    "price_value: Extract any sentences about the value or price,\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "gift\n",
    "delivery_days\n",
    "price_value\n",
    "\n",
    "text: {text}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc49eccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['text'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='For the following text, extract the following information:\\ngift: Was the item purchased as a gift for someone else? Ans\\ndelivery_days: How many days did it take for the product to \\nprice_value: Extract any sentences about the value or price,\\n\\nFormat the output as JSON with the following keys:\\ngift\\ndelivery_days\\nprice_value\\n\\ntext: {text}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b007381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"gift\": \"Yes, it was purchased as an anniversary present for the user's wife.\",\n",
      "  \"delivery_days\": 2,\n",
      "  \"price_value\": \"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "messages = prompt_template.format_messages(text = customer_review)\n",
    "response = chat.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aeab82c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4baaf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:34: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:34: SyntaxWarning: invalid escape sequence '\\ '\n",
      "C:\\Users\\18850\\AppData\\Local\\Temp\\ipykernel_9056\\2288892944.py:34: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  result = chain.invoke({\"query\": \"\"\"This leaf blower is pretty amazing. It has four settings:\\ candle blower, gentle breeze, windy city, and tornado. \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gift': \"Yes, it was purchased as an anniversary present for the user's wife.\", 'delivery_days': 2, 'price_value': \"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class OrderInfo(BaseModel):\n",
    "    gift: bool = Field(description=\"Whether a gift was delivered\")\n",
    "    delivery_days: int = Field(description=\"Number of days for delivery\")\n",
    "    price_value: float = Field(description=\"Price of the product\")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=OrderInfo)\n",
    "\n",
    "# 获取格式说明（等价于 get_format_instructions）\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"For the following text, extract the following information:\n",
    "gift: Was the item purchased as a gift for someone else? Ans\n",
    "delivery_days: How many days did it take for the product to \n",
    "price_value: Extract any sentences about the value or price,\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "gift\n",
    "delivery_days\n",
    "price_value\"\"\"),\n",
    "    (\"user\", \"{query}\")\n",
    "])\n",
    "\n",
    "# 初始化模型和 parser\n",
    "parser = JsonOutputParser(pydantic_object=OrderInfo)\n",
    "\n",
    "# 组装 chain\n",
    "chain = prompt | chat | parser\n",
    "\n",
    "# 调用\n",
    "result = chain.invoke({\"query\": \"\"\"This leaf blower is pretty amazing. It has four settings:\\ candle blower, gentle breeze, windy city, and tornado. \\\n",
    "It arrived in two days, just in time for my wife's \\\n",
    "anniversary present. \\\n",
    "I think my wife liked it so much she was speechless. \\\n",
    "So far I've been the only one using it, and I've been \\\n",
    "using it every other morning to clear the leaves on our law \\\n",
    "It's slightly more expensive than the other leaf blowers \\\n",
    "out there, but I think it's worth it for the extra features.\"\"\"})\n",
    "\n",
    "print(result)  # 输出: {'gift': True, 'delivery_days': 3, 'price_value': 99.99}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c712bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e38542d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n",
      "西湖,灵隐寺,雷峰塔,宋城,千岛湖,杭州植物园,中国丝绸博物馆,杭州动物园,九溪烟树,钱塘江\n",
      "['西湖', '灵隐寺', '雷峰塔', '宋城', '千岛湖', '杭州植物园', '中国丝绸博物馆', '杭州动物园', '九溪烟树', '钱塘江']\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"{parser_instructions}\"),\n",
    "    (\"human\", \"列出{cityName}的{viewPointNum}个著名景点。\")\n",
    "])\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "parser_instructions = output_parser.get_format_instructions()\n",
    "# 查看解析器的指令内容\n",
    "print(parser_instructions)\n",
    "\n",
    "# final_prompt = prompt.invoke({\"cityName\": \"南京\", \"viewPointNum\": 3, \"parser_instructions\": parser_instructions})\n",
    "final_prompt = prompt.format_messages(cityName=\"杭州\",\n",
    "                                      viewPointNum=10,\n",
    "                                      parser_instructions=parser_instructions)\n",
    "\n",
    "response = chat.invoke(final_prompt)\n",
    "print(response.content)\n",
    "\n",
    "ret = output_parser.invoke(response)\n",
    "print(ret)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mimillm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
